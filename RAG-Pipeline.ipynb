{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f2d9fcf0b0c45e891242a72b5122a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d59c80d554d41bea5b9435e3808b139",
              "IPY_MODEL_be524cc360be47928cbb8a49d3da7c28",
              "IPY_MODEL_60c71cb9e5f440659bc04c10bf00a162"
            ],
            "layout": "IPY_MODEL_fb992dbcc2824e3ba71bd6a002525cb9"
          }
        },
        "3d59c80d554d41bea5b9435e3808b139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5fab271196c4232be9ce66bce0aabaf",
            "placeholder": "​",
            "style": "IPY_MODEL_da24a0ec868844a7a2184134bc6a5e30",
            "value": "Batches: 100%"
          }
        },
        "be524cc360be47928cbb8a49d3da7c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_273b676bc4b24b138d349e16058494d7",
            "max": 135,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10f86c6b981a47988c555d5cbe0d2598",
            "value": 135
          }
        },
        "60c71cb9e5f440659bc04c10bf00a162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a317f7bf1f049e5bc3d47c9454fe687",
            "placeholder": "​",
            "style": "IPY_MODEL_214185c62f64408e9a59c7a08296bd48",
            "value": " 135/135 [00:07&lt;00:00, 40.60it/s]"
          }
        },
        "fb992dbcc2824e3ba71bd6a002525cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5fab271196c4232be9ce66bce0aabaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da24a0ec868844a7a2184134bc6a5e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "273b676bc4b24b138d349e16058494d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10f86c6b981a47988c555d5cbe0d2598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a317f7bf1f049e5bc3d47c9454fe687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "214185c62f64408e9a59c7a08296bd48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0241160e256c4214a7b0c687999fba7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3d7d90596fb4e9eacb8ac58454e062f",
              "IPY_MODEL_317389ffeacc44748bf0499fe9a6919d",
              "IPY_MODEL_9e5e17ebbaa944f2b8a0a6c15b146d98"
            ],
            "layout": "IPY_MODEL_493a48e5c6554b75b1de7f3fff1ffadd"
          }
        },
        "a3d7d90596fb4e9eacb8ac58454e062f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a31da82f0b42430dbdf2ec32ab487c1f",
            "placeholder": "​",
            "style": "IPY_MODEL_4a6ce40f5b2c41d7b52c0de492ab9a92",
            "value": "model.safetensors: 100%"
          }
        },
        "317389ffeacc44748bf0499fe9a6919d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bc40e4c0e8541a49cb27421cc78dc51",
            "max": 2200119864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5aa2cea3878470791a1ea0ee5dc65dc",
            "value": 2200119864
          }
        },
        "9e5e17ebbaa944f2b8a0a6c15b146d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d8e39436a454ddd852a4f595b21f5b7",
            "placeholder": "​",
            "style": "IPY_MODEL_19e17673ae044f9db7292777c04e4950",
            "value": " 2.20G/2.20G [00:24&lt;00:00, 105MB/s]"
          }
        },
        "493a48e5c6554b75b1de7f3fff1ffadd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a31da82f0b42430dbdf2ec32ab487c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a6ce40f5b2c41d7b52c0de492ab9a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bc40e4c0e8541a49cb27421cc78dc51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5aa2cea3878470791a1ea0ee5dc65dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d8e39436a454ddd852a4f595b21f5b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e17673ae044f9db7292777c04e4950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54a58296a374406492d158bf81e413dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bcd7cd54db24235b4bcacebccf2c663",
              "IPY_MODEL_c13d3dfe5d6e4ad7a986766bcff9b994",
              "IPY_MODEL_3d5f5b168c434a5787446a76f3d91cb3"
            ],
            "layout": "IPY_MODEL_9a1bca19ccc24086bd4fc034adba7e24"
          }
        },
        "9bcd7cd54db24235b4bcacebccf2c663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50a1e51b863f4eb2a416d9f42f4232fa",
            "placeholder": "​",
            "style": "IPY_MODEL_0c493c5c78c44f0f8788f027e1bed013",
            "value": "generation_config.json: 100%"
          }
        },
        "c13d3dfe5d6e4ad7a986766bcff9b994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0af0b24d1b374a21949bb20a21a8ff8a",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d798162bd8b4b3ebc0fb825365d9b47",
            "value": 124
          }
        },
        "3d5f5b168c434a5787446a76f3d91cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd5afdda79854ee194180cd4265f73cf",
            "placeholder": "​",
            "style": "IPY_MODEL_4eec68d2712643b48a7bebf2dcf333f8",
            "value": " 124/124 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "9a1bca19ccc24086bd4fc034adba7e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50a1e51b863f4eb2a416d9f42f4232fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c493c5c78c44f0f8788f027e1bed013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0af0b24d1b374a21949bb20a21a8ff8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d798162bd8b4b3ebc0fb825365d9b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd5afdda79854ee194180cd4265f73cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eec68d2712643b48a7bebf2dcf333f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment"
      ],
      "metadata": {
        "id": "_EzAtwzm-rQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# INSTALLATION\n",
        "# ============================================================================\n",
        "print(\"Installing required packages...\")\n",
        "# Force update bitsandbytes and transformers\n",
        "!pip install -q -U bitsandbytes transformers accelerate chromadb sentence-transformers pandas torch\n",
        "print(\"✓ Installation complete\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMV6ADMILRD8",
        "outputId": "fd87460e-a21f-43a4-d8e5-dd62d0512a37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "✓ Installation complete\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2iFJhrcqnm4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "EVENT INTELLIGENCE RAG SYSTEM - FIXED VERSION\n",
        "================================================================================\n",
        "Assignment: Build a RAG system for operational event intelligence\n",
        "\n",
        "- Enhanced retrieval with metadata filtering for exact ID matches\n",
        "- Hybrid search (exact + semantic)\n",
        "- Better event ID extraction and matching\n",
        "- Data validation checks\n",
        "\n",
        "================================================================================\n",
        "\"\"\"\n",
        "# ============================================================================\n",
        "# INSTALLATION\n",
        "# ============================================================================\n",
        "print(\"Installing required packages...\")\n",
        "# Force update bitsandbytes and transformers\n",
        "!pip install -q -U bitsandbytes transformers accelerate chromadb sentence-transformers pandas torch\n",
        "print(\"✓ Installation complete\\n\")\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import json\n",
        "import re\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "import torch\n",
        "from google.colab import files\n",
        "\n",
        "print(\"✓ All packages imported successfully\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: DATA INGESTION & SQL SETUP\n",
        "# ============================================================================\n",
        "\n",
        "def upload_csv_file():\n",
        "    print(\"=\"*70)\n",
        "    print(\"[STEP 1: DATA INGESTION & SQL SETUP]\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nPlease upload your CSV file...\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        raise ValueError(\"❌ No file uploaded!\")\n",
        "\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    print(f\"✓ File uploaded: {filename}\")\n",
        "\n",
        "    df = pd.read_csv(filename, low_memory=False)\n",
        "    print(f\"✓ Loaded {len(df)} records with {len(df.columns)} columns\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_sqlite_database(df):\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"Creating SQLite database...\")\n",
        "\n",
        "    db_path = \"event_details.db\"\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"DROP TABLE IF EXISTS event_details\")\n",
        "    df.to_sql('event_details', conn, if_exists='replace', index=False)\n",
        "\n",
        "    cursor.execute(\"SELECT COUNT(*) FROM event_details\")\n",
        "    count = cursor.fetchone()[0]\n",
        "\n",
        "    print(f\"✓ Database created with {count} rows\")\n",
        "    return conn\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: FEATURE ENGINEERING\n",
        "# ============================================================================\n",
        "\n",
        "def parse_json_safely(json_str):\n",
        "  #data has JSON \"hidden\" inside text strings. This function safely unpacks that data.\n",
        "  # If the JSON is broken or empty, it returns an empty dictionary instead of crashing the program.\n",
        "\n",
        "    if pd.isna(json_str) or json_str == '':\n",
        "        return {}\n",
        "    try:\n",
        "        if isinstance(json_str, str):\n",
        "            return json.loads(json_str)\n",
        "        return {}\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "def create_event_narrative(row):\n",
        "  #It gathers facts from 100+ columns (Location, Time, Priority, etc.)\n",
        "  #and joins them into a single, human-readable paragraph. This is what the AI actually \"reads.\"\n",
        "    narrative_parts = []\n",
        "\n",
        "    if pd.notna(row.get('EVENT_ID')):\n",
        "        narrative_parts.append(f\"Incident ID {row['EVENT_ID']}\")\n",
        "    if pd.notna(row.get('ALARM_ID')):\n",
        "        narrative_parts.append(f\"Alarm {row['ALARM_ID']}\")\n",
        "    if pd.notna(row.get('ALARM_NAME')):\n",
        "        narrative_parts.append(f\"Type: {row['ALARM_NAME']}\")\n",
        "    if pd.notna(row.get('CATEGORY_NAME')):\n",
        "        narrative_parts.append(f\"Category: {row['CATEGORY_NAME']}\")\n",
        "    if pd.notna(row.get('PRIORITY')):\n",
        "        narrative_parts.append(f\"Priority Level: {row['PRIORITY']}\")\n",
        "    if pd.notna(row.get('SEVERITY')):\n",
        "        narrative_parts.append(f\"Severity: {row['SEVERITY']}\")\n",
        "    if pd.notna(row.get('URGENCY')):\n",
        "        narrative_parts.append(f\"Urgency: {row['URGENCY']}\")\n",
        "    if pd.notna(row.get('LOCATION')):\n",
        "        narrative_parts.append(f\"Location: {row['LOCATION']}\")\n",
        "    if pd.notna(row.get('SITE_NAME')):\n",
        "        narrative_parts.append(f\"Site: {row['SITE_NAME']}\")\n",
        "    if pd.notna(row.get('JURISDICTION_NAME')):\n",
        "        narrative_parts.append(f\"Jurisdiction: {row['JURISDICTION_NAME']}\")\n",
        "    if pd.notna(row.get('LATITUDE')) and pd.notna(row.get('LONGITUDE')):\n",
        "        narrative_parts.append(f\"Coordinates: ({row['LATITUDE']}, {row['LONGITUDE']})\")\n",
        "    if pd.notna(row.get('ALARM_GENERATED_TIME')):\n",
        "        narrative_parts.append(f\"Generated at: {row['ALARM_GENERATED_TIME']}\")\n",
        "    if pd.notna(row.get('EVENT_CREATED_TIME')):\n",
        "        narrative_parts.append(f\"Created at: {row['EVENT_CREATED_TIME']}\")\n",
        "    if pd.notna(row.get('EVENT_STATUS')):\n",
        "        narrative_parts.append(f\"Event Status: {row['EVENT_STATUS']}\")\n",
        "    if pd.notna(row.get('ALARM_STATUS')):\n",
        "        narrative_parts.append(f\"Alarm Status: {row['ALARM_STATUS']}\")\n",
        "    if pd.notna(row.get('PRIMARY_AGENCY')):\n",
        "        narrative_parts.append(f\"Primary Agency: {row['PRIMARY_AGENCY']}\")\n",
        "    if pd.notna(row.get('SECONDARY_AGENCY')):\n",
        "        narrative_parts.append(f\"Secondary Agencies: {row['SECONDARY_AGENCY']}\")\n",
        "    if pd.notna(row.get('USER_NAME')):\n",
        "        narrative_parts.append(f\"Personnel: {row['USER_NAME']}\")\n",
        "    if pd.notna(row.get('STATION_NAME')):\n",
        "        narrative_parts.append(f\"Station: {row['STATION_NAME']}\")\n",
        "    if pd.notna(row.get('SOP_NAME')):\n",
        "        narrative_parts.append(f\"SOP: {row['SOP_NAME']}\")\n",
        "    if pd.notna(row.get('SOP_DESCRIPTION')):\n",
        "        sop_desc = str(row['SOP_DESCRIPTION'])[:200]\n",
        "        narrative_parts.append(f\"SOP Description: {sop_desc}\")\n",
        "    if pd.notna(row.get('SOP_DOCUMENT_URL')):\n",
        "        narrative_parts.append(f\"SOP Document: {row['SOP_DOCUMENT_URL']}\")\n",
        "\n",
        "    if pd.notna(row.get('ADDITIONAL_DETAILS')):\n",
        "        details = parse_json_safely(row['ADDITIONAL_DETAILS'])\n",
        "        if details:\n",
        "            if 'incidentNarrative' in details:\n",
        "                narrative_parts.append(f\"Narrative: {details['incidentNarrative']}\")\n",
        "            if 'BuildingName' in details:\n",
        "                narrative_parts.append(f\"Building: {details['BuildingName']}\")\n",
        "            if 'BuildingFloor' in details:\n",
        "                narrative_parts.append(f\"Floor: {details['BuildingFloor']}\")\n",
        "            if 'BuildingNumber' in details:\n",
        "                narrative_parts.append(f\"Building Number: {details['BuildingNumber']}\")\n",
        "            if 'numberOfPeopleInEmergency' in details:\n",
        "                narrative_parts.append(f\"People Affected: {details['numberOfPeopleInEmergency']}\")\n",
        "            if 'incidentInjuries' in details:\n",
        "                narrative_parts.append(f\"Injuries: {details['incidentInjuries']}\")\n",
        "            if 'roadCondition' in details:\n",
        "                narrative_parts.append(f\"Road Condition: {details['roadCondition']}\")\n",
        "            if 'nearbyLandmarks' in details:\n",
        "                narrative_parts.append(f\"Nearby: {details['nearbyLandmarks']}\")\n",
        "            if 'callerName' in details:\n",
        "                narrative_parts.append(f\"Reported by: {details['callerName']}\")\n",
        "\n",
        "    if pd.notna(row.get('REC_DATA')):\n",
        "        rec_data = parse_json_safely(row['REC_DATA'])\n",
        "        if rec_data and 'stationRec' in rec_data:\n",
        "            station_info = rec_data['stationRec']\n",
        "            if 'data' in station_info and station_info['data']:\n",
        "                station = station_info['data'][0]\n",
        "                narrative_parts.append(f\"Nearest Station: {station.get('name', 'N/A')}\")\n",
        "                narrative_parts.append(f\"Distance: {station.get('distance_km', 'N/A')} km\")\n",
        "                eta_seconds = station.get('time_seconds', 0)\n",
        "                eta_minutes = int(eta_seconds) // 60 if eta_seconds else 0\n",
        "                narrative_parts.append(f\"Estimated Time: {eta_minutes} minutes\")\n",
        "                if 'equipment' in station:\n",
        "                    narrative_parts.append(f\"Available Equipment: {len(station['equipment'])} units\")\n",
        "\n",
        "    if pd.notna(row.get('PHONE')):\n",
        "        narrative_parts.append(f\"Contact: {row['PHONE']}\")\n",
        "    if pd.notna(row.get('NAME_CONTACT')):\n",
        "        narrative_parts.append(f\"Contact Person: {row['NAME_CONTACT']}\")\n",
        "    if pd.notna(row.get('DEVICE_NAME')):\n",
        "        narrative_parts.append(f\"Device: {row['DEVICE_NAME']}\")\n",
        "    if pd.notna(row.get('COMPONENT_ID')):\n",
        "        narrative_parts.append(f\"Component ID: {row['COMPONENT_ID']}\")\n",
        "\n",
        "    narrative = \". \".join(narrative_parts)\n",
        "    if narrative:\n",
        "        narrative += \".\"\n",
        "\n",
        "    return narrative\n",
        "\n",
        "def engineer_features(df):\n",
        "  #The \"Manager\" function. It runs the narrative creator on every row and creates extra metadata columns\n",
        "  #(like month or urgency) that help the search engine filter data later.\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"[STEP 2: FEATURE ENGINEERING]\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    df_enhanced = df.copy()\n",
        "    df_enhanced['event_text'] = df_enhanced.apply(create_event_narrative, axis=1)\n",
        "    print(f\"✓ Created event_text for {len(df_enhanced)} records\")\n",
        "\n",
        "    df_enhanced['priority'] = df_enhanced['PRIORITY'].fillna('Unknown').astype(str)\n",
        "    df_enhanced['component_id'] = df_enhanced['COMPONENT_ID'].fillna('Unknown').astype(str)\n",
        "    df_enhanced['severity'] = df_enhanced['SEVERITY'].fillna('Unknown').astype(str)\n",
        "    df_enhanced['urgency'] = df_enhanced['URGENCY'].fillna('Unknown').astype(str)\n",
        "\n",
        "    if 'ALARM_GENERATED_TIME' in df_enhanced.columns:\n",
        "        df_enhanced['month'] = pd.to_datetime(df_enhanced['ALARM_GENERATED_TIME'], errors='coerce').dt.month\n",
        "        df_enhanced['month'] = df_enhanced['month'].fillna(0).astype(int)\n",
        "    else:\n",
        "        df_enhanced['month'] = 0\n",
        "\n",
        "    print(\"\\n🔍 Checking for test events...\")\n",
        "    test_events = ['INC001572', 'INC001573', 'INC001574']\n",
        "    for event_id in test_events:\n",
        "        exists = (df_enhanced['EVENT_ID'] == event_id).any()\n",
        "        if exists:\n",
        "            print(f\"✓ {event_id} found\")\n",
        "        else:\n",
        "            print(f\"❌ {event_id} NOT found\")\n",
        "\n",
        "    if not any((df_enhanced['EVENT_ID'] == e).any() for e in test_events):\n",
        "        print(f\"\\n⚠️  Sample IDs: {df_enhanced['EVENT_ID'].head(10).tolist()}\")\n",
        "\n",
        "    return df_enhanced\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: TEXT CHUNKING\n",
        "# ============================================================================\n",
        "\n",
        "def chunk_text_with_overlap(text, chunk_size=500, overlap=50):\n",
        "  # Large documents are hard for AI to digest. This function slices long narratives into smaller pieces (500 characters).\n",
        "  # It uses overlap so that the end of one slice and the start of the next share some text, ensuring no context is lost \"at the edges.\"\n",
        "\n",
        "\n",
        "    if not text or len(text) <= chunk_size:\n",
        "        return [text] if text else []\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        # This part looks backward from the 500th character to find the last period (.), exclamation mark (!), or question mark (?).\n",
        "        #The Result: It identifies the end of the last complete sentence within that 500-character limit.\n",
        "        if end < len(text):\n",
        "            last_period = text[start:end].rfind('.')\n",
        "            last_exclamation = text[start:end].rfind('!')\n",
        "            last_question = text[start:end].rfind('?')\n",
        "            boundary = max(last_period, last_exclamation, last_question)\n",
        "            # If a punctuation mark was found, the code moves the \"cut\" point to exactly after that mark. This ensures every chunk is a set of complete sentences.\n",
        "            if boundary != -1:\n",
        "                end = start + boundary + 1\n",
        "\n",
        "        chunk = text[start:end].strip()\n",
        "        if chunk:\n",
        "            chunks.append(chunk)\n",
        "\n",
        "        start = end - overlap #This is the most clever part. Instead of starting the next chunk exactly where the last one ended, it \"steps back\" by 50 characters (the overlap).\n",
        "        if start <= 0:\n",
        "            start = end\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def create_chunks_with_metadata(df, chunk_size=500, overlap=50):\n",
        "  #Takes those slices and attaches \"ID Tags\" (metadata) to them.\n",
        "  # It ensures every slice knows which EVENT_ID it belongs to, which is why your search is accurate.\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"[STEP 3: TEXT CHUNKING]\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    all_chunks = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        text = row.get('event_text', '')\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        text_chunks = chunk_text_with_overlap(text, chunk_size, overlap)\n",
        "\n",
        "        for chunk_idx, chunk_text in enumerate(text_chunks):\n",
        "            unique_id = f\"{row.get('EVENT_ID', idx)}_{chunk_idx}_{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "            chunk_data = {\n",
        "                'chunk_id': unique_id,\n",
        "                'text': chunk_text,\n",
        "                'alarm_id': str(row.get('ALARM_ID', '')),\n",
        "                'event_id': str(row.get('EVENT_ID', '')),\n",
        "                'priority': str(row.get('priority', '')),\n",
        "                'component_id': str(row.get('component_id', '')),\n",
        "                'severity': str(row.get('severity', '')),\n",
        "                'urgency': str(row.get('urgency', '')),\n",
        "                'location': str(row.get('LOCATION', '')),\n",
        "                'category': str(row.get('CATEGORY_NAME', '')),\n",
        "                'status': str(row.get('EVENT_STATUS', '')),\n",
        "                'jurisdiction': str(row.get('JURISDICTION_NAME', '')),\n",
        "                'month': int(row.get('month', 0))\n",
        "            }\n",
        "\n",
        "            all_chunks.append(chunk_data)\n",
        "\n",
        "    print(f\"✓ Created {len(all_chunks)} chunks from {len(df)} events\")\n",
        "    return all_chunks\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: EMBEDDINGS & VECTOR DATABASE\n",
        "# ============================================================================\n",
        "\n",
        "def load_embedding_model(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "  #Loads a specialized model that turns human text into a list of numbers (a vector).\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"[STEP 4: EMBEDDINGS & VECTOR DATABASE]\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    model = SentenceTransformer(model_name)\n",
        "    print(\"✓ Embedding model loaded\")\n",
        "    return model\n",
        "\n",
        "def setup_chromadb():\n",
        "  #Initializes ChromaDB, a \"Vector Database.\"\n",
        "  #Unlike a normal database, this one can find information based on meaning rather than just exact words.\n",
        "    client = chromadb.Client(Settings(anonymized_telemetry=False, allow_reset=True))\n",
        "\n",
        "    try:\n",
        "        client.delete_collection(\"event_intelligence\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    collection = client.create_collection(\n",
        "        name=\"event_intelligence\",\n",
        "        metadata={\"hnsw:space\": \"cosine\"}\n",
        "    )\n",
        "\n",
        "    print(\"✓ ChromaDB initialized\")\n",
        "    return client, collection\n",
        "\n",
        "def generate_and_store_embeddings(chunks, embedding_model, collection):\n",
        "  #Turns all your text chunks into numbers and saves them in ChromaDB.\n",
        "    texts = [chunk['text'] for chunk in chunks]\n",
        "    embeddings = embedding_model.encode(texts, show_progress_bar=True, batch_size=32)\n",
        "\n",
        "    ids = [chunk['chunk_id'] for chunk in chunks]\n",
        "    documents = texts\n",
        "    metadatas = [\n",
        "        {\n",
        "            'alarm_id': chunk['alarm_id'],\n",
        "            'event_id': chunk['event_id'],\n",
        "            'priority': chunk['priority'],\n",
        "            'component_id': chunk['component_id'],\n",
        "            'severity': chunk['severity'],\n",
        "            'urgency': chunk['urgency'],\n",
        "            'location': chunk['location'],\n",
        "            'category': chunk['category'],\n",
        "            'status': chunk['status'],\n",
        "            'jurisdiction': chunk['jurisdiction'],\n",
        "            'month': chunk['month']\n",
        "        }\n",
        "        for chunk in chunks\n",
        "    ]\n",
        "\n",
        "    batch_size = 1000\n",
        "    for i in range(0, len(ids), batch_size):\n",
        "        end_idx = min(i + batch_size, len(ids))\n",
        "        collection.add(\n",
        "            embeddings=embeddings[i:end_idx].tolist(),\n",
        "            documents=documents[i:end_idx],\n",
        "            metadatas=metadatas[i:end_idx],\n",
        "            ids=ids[i:end_idx]\n",
        "        )\n",
        "\n",
        "    print(f\"✓ Stored {len(chunks)} embeddings\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: ENHANCED RETRIEVAL\n",
        "# ============================================================================\n",
        "\n",
        "def retrieve_by_exact_id(event_id, collection, max_results=20):\n",
        "  #It tells ChromaDB: \"Ignore the AI for a second and just find every piece of text tagged with this specific INC001572 ID.\n",
        "    \"\"\"Get ALL chunks for specific event ID\"\"\"\n",
        "    try:\n",
        "        results = collection.get(\n",
        "            where={\"event_id\": event_id.upper()},\n",
        "            limit=max_results\n",
        "        )\n",
        "\n",
        "        retrieved_chunks = []\n",
        "        if results['documents']:\n",
        "            print(f\"  ✓ Found {len(results['documents'])} chunks for {event_id}\")\n",
        "            for i in range(len(results['documents'])):\n",
        "                chunk_data = {\n",
        "                    'text': results['documents'][i],\n",
        "                    'metadata': results['metadatas'][i],\n",
        "                    'distance': 0.0,\n",
        "                    'relevance_score': 1.0\n",
        "                }\n",
        "                retrieved_chunks.append(chunk_data)\n",
        "        return retrieved_chunks\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Error: {e}\")\n",
        "        return []\n",
        "\n",
        "def retrieve_semantic(query, collection, embedding_model, top_k=5, where_filter=None):\n",
        "  #This is the \"Smart Search.\" It looks for concepts. If you ask about \"flooding,\" it will find \"water leakage\" because it understands they are similar concepts.\n",
        "    \"\"\"Semantic search with optional filtering\"\"\"\n",
        "    query_embedding = embedding_model.encode([query])[0]\n",
        "\n",
        "    try:\n",
        "        if where_filter:\n",
        "            results = collection.query(\n",
        "                query_embeddings=[query_embedding.tolist()],\n",
        "                n_results=top_k,\n",
        "                where=where_filter\n",
        "            )\n",
        "        else:\n",
        "            results = collection.query(\n",
        "                query_embeddings=[query_embedding.tolist()],\n",
        "                n_results=top_k\n",
        "            )\n",
        "\n",
        "        retrieved_chunks = []\n",
        "        if results['documents'] and results['documents'][0]:\n",
        "            for i in range(len(results['documents'][0])):\n",
        "                chunk_data = {\n",
        "                    'text': results['documents'][0][i],\n",
        "                    'metadata': results['metadatas'][0][i],\n",
        "                    'distance': results['distances'][0][i],\n",
        "                    'relevance_score': 1 - results['distances'][0][i]\n",
        "                }\n",
        "                retrieved_chunks.append(chunk_data)\n",
        "        return retrieved_chunks\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Error: {e}\")\n",
        "        return []\n",
        "\n",
        "def hybrid_retrieve(query, collection, embedding_model, top_k=5):\n",
        "  #It uses a Regex (Regular Expression) to see if you typed an Incident ID. If you did, it uses the Exact Search; if you didn't, it uses Semantic Search.\n",
        "    \"\"\"Hybrid: exact match for IDs, semantic for general queries\"\"\"\n",
        "    event_id_match = re.search(r'INC\\d+', query, re.IGNORECASE)\n",
        "\n",
        "    if event_id_match:\n",
        "        event_id = event_id_match.group(0).upper()\n",
        "        print(f\"  🎯 Detected Event ID: {event_id}\")\n",
        "\n",
        "        chunks = retrieve_by_exact_id(event_id, collection, max_results=20)\n",
        "        if chunks:\n",
        "            return chunks[:top_k]\n",
        "        else:\n",
        "            print(f\"  ⚠ No exact match, trying semantic search\")\n",
        "\n",
        "    print(f\"  🔍 Semantic search (top_k={top_k})\")\n",
        "    return retrieve_semantic(query, collection, embedding_model, top_k)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: RAG PROMPT & GENERATION\n",
        "# ============================================================================\n",
        "\n",
        "def create_rag_prompt(query, retrieved_chunks):\n",
        "  #This takes the found chunks and packages them into a strict instruction for the LLM.\n",
        "  #It tells the AI: \"Here is the data, answer the user's question, and do not make anything up.\"\n",
        "    context_parts = []\n",
        "    for i, chunk in enumerate(retrieved_chunks, 1):\n",
        "        context_parts.append(f\"[Context {i}]\")\n",
        "        context_parts.append(f\"Event: {chunk['metadata'].get('event_id', 'N/A')}\")\n",
        "        context_parts.append(f\"Priority: {chunk['metadata'].get('priority', 'N/A')}\")\n",
        "        context_parts.append(f\"Category: {chunk['metadata'].get('category', 'N/A')}\")\n",
        "        context_parts.append(f\"Content: {chunk['text']}\")\n",
        "        context_parts.append(\"\")\n",
        "\n",
        "    context_text = \"\\n\".join(context_parts)\n",
        "\n",
        "    prompt = f\"\"\"You are an intelligent assistant for an operational event intelligence system. Answer questions about incidents based ONLY on the provided context.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Use ONLY information from the context\n",
        "2. If answer not in context, say \"I cannot find this information in the available data\"\n",
        "3. Be specific and cite event IDs\n",
        "4. List all matching events if multiple\n",
        "\n",
        "CONTEXT:\n",
        "{context_text}\n",
        "\n",
        "QUESTION: {query}\n",
        "\n",
        "ANSWER: \"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "def load_llm_model(model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n",
        "  #Loads TinyLlama using 4-bit quantization.\n",
        "  #This \"shrinks\" the model so it can run on the free T4 GPU without running out of memory.\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"[LOADING LLM FOR RAG]\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        quantization_config=quantization_config,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    text_generator = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.7,\n",
        "        top_p=0.95,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "    print(\"✓ LLM ready\")\n",
        "    return tokenizer, text_generator\n",
        "\n",
        "def generate_answer(prompt, text_generator):\n",
        "  #The final step. It sends the prompt to TinyLlama and cleans up the text it sends back to give you a neat answer.\n",
        "    try:\n",
        "        response = text_generator(\n",
        "            prompt,\n",
        "            max_new_tokens=512,\n",
        "            num_return_sequences=1,\n",
        "            pad_token_id=text_generator.tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        generated_text = response[0]['generated_text']\n",
        "\n",
        "        if \"ANSWER:\" in generated_text:\n",
        "            answer = generated_text.split(\"ANSWER:\")[-1].strip()\n",
        "        else:\n",
        "            answer = generated_text[len(prompt):].strip()\n",
        "\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def query_rag_system(question, collection, embedding_model, text_generator, top_k=5):\n",
        "  #It connects the Retrieval, Prompting, and Generation steps into one single command.\n",
        "    \"\"\"Complete RAG pipeline\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"QUERY: {question}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n[RETRIEVAL]\")\n",
        "    retrieved_chunks = hybrid_retrieve(question, collection, embedding_model, top_k)\n",
        "\n",
        "    print(f\"✓ Retrieved {len(retrieved_chunks)} chunks\")\n",
        "    for i, chunk in enumerate(retrieved_chunks, 1):\n",
        "        print(f\"\\n  Chunk {i}:\")\n",
        "        print(f\"    Event: {chunk['metadata'].get('event_id', 'N/A')}\")\n",
        "        print(f\"    Priority: {chunk['metadata'].get('priority', 'N/A')}\")\n",
        "        print(f\"    Score: {chunk.get('relevance_score', 0):.3f}\")\n",
        "        print(f\"    Text: {chunk['text'][:150]}...\")\n",
        "\n",
        "    print(\"\\n[GENERATING ANSWER]\")\n",
        "    prompt = create_rag_prompt(question, retrieved_chunks)\n",
        "    answer = generate_answer(prompt, text_generator)\n",
        "\n",
        "    print(\"\\n[ANSWER]\")\n",
        "    print(\"-\"*70)\n",
        "    print(answer)\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    return {\n",
        "        'question': question,\n",
        "        'answer': answer,\n",
        "        'retrieved_chunks': retrieved_chunks,\n",
        "        'num_chunks': len(retrieved_chunks)\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# VALIDATION TESTS\n",
        "# ============================================================================\n",
        "\n",
        "def run_validation_tests(collection, embedding_model, text_generator):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VALIDATION SCENARIOS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    scenario1_questions = [\n",
        "        \"Give me complete details on the Event INC001572\",\n",
        "        \"What are the SOP steps recommended for INC001572?\",\n",
        "        \"What actions were taken for the incident INC001572?\",\n",
        "        \"Who was the workforce dispatched for the event INC001572 and what is their current status?\",\n",
        "        \"What are the buildings affected for the water leakage event INC001572?\",\n",
        "        \"When and where did incident INC001572 happen and what is the current status?\",\n",
        "        \"List the contact numbers of all building in-charges notified regarding event INC001572\"\n",
        "    ]\n",
        "\n",
        "    scenario1_results = []\n",
        "    for i, question in enumerate(scenario1_questions, 1):\n",
        "        print(f\"\\n### Scenario 1 - Question {i}/{len(scenario1_questions)} ###\")\n",
        "        result = query_rag_system(question, collection, embedding_model, text_generator, top_k=5)\n",
        "        scenario1_results.append(result)\n",
        "\n",
        "    scenario2_questions = [\n",
        "        \"How many pending water leakage events are there?\",\n",
        "        \"List recent water leakage events that happened in Bangalore at night time\",\n",
        "        \"How many water leakage events happened in the last week?\",\n",
        "        \"What are the Standard Operating Procedures for water leakage events?\",\n",
        "        \"Who was the resource sent for the water leakage event that happened today in Bangalore?\",\n",
        "        \"Show me the response plan being executed for the water leak incident at Zone 5\",\n",
        "        \"Show workforce assigned to all incidents between Oct 25-29, 2025\"\n",
        "    ]\n",
        "\n",
        "    scenario2_results = []\n",
        "    for i, question in enumerate(scenario2_questions, 1):\n",
        "        print(f\"\\n### Scenario 2 - Question {i}/{len(scenario2_questions)} ###\")\n",
        "        result = query_rag_system(question, collection, embedding_model, text_generator, top_k=5)\n",
        "        scenario2_results.append(result)\n",
        "\n",
        "    return scenario1_results, scenario2_results\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EVENT INTELLIGENCE RAG SYSTEM - COMPLETE PIPELINE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    df = upload_csv_file()\n",
        "    conn = create_sqlite_database(df)\n",
        "    df_engineered = engineer_features(df)\n",
        "    chunks = create_chunks_with_metadata(df_engineered, chunk_size=500, overlap=50)\n",
        "    embedding_model = load_embedding_model()\n",
        "    client, collection = setup_chromadb()\n",
        "    generate_and_store_embeddings(chunks, embedding_model, collection)\n",
        "    tokenizer, text_generator = load_llm_model()\n",
        "\n",
        "    scenario1_results, scenario2_results = run_validation_tests(\n",
        "        collection, embedding_model, text_generator\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"✓ SYSTEM READY!\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return {\n",
        "        'database_connection': conn,\n",
        "        'dataframe': df_engineered,\n",
        "        'chunks': chunks,\n",
        "        'embedding_model': embedding_model,\n",
        "        'chromadb_client': client,\n",
        "        'collection': collection,\n",
        "        'tokenizer': tokenizer,\n",
        "        'text_generator': text_generator,\n",
        "        'scenario1_results': scenario1_results,\n",
        "        'scenario2_results': scenario2_results\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    system_components = main()\n",
        "\n",
        "    conn = system_components['database_connection']\n",
        "    df = system_components['dataframe']\n",
        "    chunks = system_components['chunks']\n",
        "    embedding_model = system_components['embedding_model']\n",
        "    client = system_components['chromadb_client']\n",
        "    collection = system_components['collection']\n",
        "    tokenizer = system_components['tokenizer']\n",
        "    text_generator = system_components['text_generator']\n",
        "\n",
        "    print(\"\\nTo ask custom questions:\")\n",
        "    print(\">>> result = query_rag_system('Your question', collection, embedding_model, text_generator)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2f2d9fcf0b0c45e891242a72b5122a87",
            "3d59c80d554d41bea5b9435e3808b139",
            "be524cc360be47928cbb8a49d3da7c28",
            "60c71cb9e5f440659bc04c10bf00a162",
            "fb992dbcc2824e3ba71bd6a002525cb9",
            "b5fab271196c4232be9ce66bce0aabaf",
            "da24a0ec868844a7a2184134bc6a5e30",
            "273b676bc4b24b138d349e16058494d7",
            "10f86c6b981a47988c555d5cbe0d2598",
            "1a317f7bf1f049e5bc3d47c9454fe687",
            "214185c62f64408e9a59c7a08296bd48",
            "0241160e256c4214a7b0c687999fba7a",
            "a3d7d90596fb4e9eacb8ac58454e062f",
            "317389ffeacc44748bf0499fe9a6919d",
            "9e5e17ebbaa944f2b8a0a6c15b146d98",
            "493a48e5c6554b75b1de7f3fff1ffadd",
            "a31da82f0b42430dbdf2ec32ab487c1f",
            "4a6ce40f5b2c41d7b52c0de492ab9a92",
            "4bc40e4c0e8541a49cb27421cc78dc51",
            "b5aa2cea3878470791a1ea0ee5dc65dc",
            "0d8e39436a454ddd852a4f595b21f5b7",
            "19e17673ae044f9db7292777c04e4950",
            "54a58296a374406492d158bf81e413dd",
            "9bcd7cd54db24235b4bcacebccf2c663",
            "c13d3dfe5d6e4ad7a986766bcff9b994",
            "3d5f5b168c434a5787446a76f3d91cb3",
            "9a1bca19ccc24086bd4fc034adba7e24",
            "50a1e51b863f4eb2a416d9f42f4232fa",
            "0c493c5c78c44f0f8788f027e1bed013",
            "0af0b24d1b374a21949bb20a21a8ff8a",
            "1d798162bd8b4b3ebc0fb825365d9b47",
            "dd5afdda79854ee194180cd4265f73cf",
            "4eec68d2712643b48a7bebf2dcf333f8"
          ]
        },
        "id": "qSbIFigVbOIm",
        "outputId": "1d5ad26c-79f4-4c52-94a2-51ffa63c486a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "✓ Installation complete\n",
            "\n",
            "✓ All packages imported successfully\n",
            "\n",
            "\n",
            "======================================================================\n",
            "EVENT INTELLIGENCE RAG SYSTEM - COMPLETE PIPELINE\n",
            "======================================================================\n",
            "======================================================================\n",
            "[STEP 1: DATA INGESTION & SQL SETUP]\n",
            "======================================================================\n",
            "\n",
            "Please upload your CSV file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cebe86c6-aa51-4533-a526-d1cb6c636bd7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cebe86c6-aa51-4533-a526-d1cb6c636bd7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving V_EVENT_DETAILS_202512311554.csv to V_EVENT_DETAILS_202512311554 (1).csv\n",
            "✓ File uploaded: V_EVENT_DETAILS_202512311554 (1).csv\n",
            "✓ Loaded 3921 records with 104 columns\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Creating SQLite database...\n",
            "✓ Database created with 3921 rows\n",
            "\n",
            "======================================================================\n",
            "[STEP 2: FEATURE ENGINEERING]\n",
            "======================================================================\n",
            "✓ Created event_text for 3921 records\n",
            "\n",
            "🔍 Checking for test events...\n",
            "✓ INC001572 found\n",
            "✓ INC001573 found\n",
            "✓ INC001574 found\n",
            "\n",
            "======================================================================\n",
            "[STEP 3: TEXT CHUNKING]\n",
            "======================================================================\n",
            "✓ Created 4298 chunks from 3921 events\n",
            "\n",
            "======================================================================\n",
            "[STEP 4: EMBEDDINGS & VECTOR DATABASE]\n",
            "======================================================================\n",
            "✓ Embedding model loaded\n",
            "✓ ChromaDB initialized\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/135 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f2d9fcf0b0c45e891242a72b5122a87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Stored 4298 embeddings\n",
            "\n",
            "======================================================================\n",
            "[LOADING LLM FOR RAG]\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0241160e256c4214a7b0c687999fba7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54a58296a374406492d158bf81e413dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ LLM ready\n",
            "\n",
            "======================================================================\n",
            "VALIDATION SCENARIOS\n",
            "======================================================================\n",
            "\n",
            "### Scenario 1 - Question 1/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: Give me complete details on the Event INC001572\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🎯 Detected Event ID: INC001572\n",
            "  ✓ Found 1 chunks for INC001572\n",
            "✓ Retrieved 1 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC001572\n",
            "    Priority: Critical\n",
            "    Score: 1.000\n",
            "    Text: Incident ID INC001572. Alarm 20574. Type: Driver Identified ADAS. Priority Level: Critical. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emi...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "Answer: The primary agency for the incident is the Police.\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 1 - Question 2/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: What are the SOP steps recommended for INC001572?\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🎯 Detected Event ID: INC001572\n",
            "  ✓ Found 1 chunks for INC001572\n",
            "✓ Retrieved 1 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC001572\n",
            "    Priority: Critical\n",
            "    Score: 1.000\n",
            "    Text: Incident ID INC001572. Alarm 20574. Type: Driver Identified ADAS. Priority Level: Critical. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emi...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "1. Use ONLY information from the context\n",
            "2. If answer not in context, say \"I cannot find this information in the available data\"\n",
            "3. Be specific and cite event IDs\n",
            "4. List all matching events if multiple\n",
            "\n",
            "CONTEXT:\n",
            "[Context 1]\n",
            "Event: INC001572\n",
            "Priority: Critical\n",
            "Category: nan\n",
            "Content: Incident ID INC001572. Alarm 20574. Type: Driver Identified ADAS. Priority Level: Critical. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emirates. Coordinates: (21.418555, 96.108398). Generated at: 2025-\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 1 - Question 3/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: What actions were taken for the incident INC001572?\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🎯 Detected Event ID: INC001572\n",
            "  ✓ Found 1 chunks for INC001572\n",
            "✓ Retrieved 1 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC001572\n",
            "    Priority: Critical\n",
            "    Score: 1.000\n",
            "    Text: Incident ID INC001572. Alarm 20574. Type: Driver Identified ADAS. Priority Level: Critical. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emi...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "The primary agency for this incident was the Police. They took the following actions:\n",
            "- Awareness of the incident.\n",
            "- Investigation of the incident.\n",
            "- Reporting the incident to other agencies.\n",
            "- Notifying the public of the incident.\n",
            "- Collaborating with the civil defense and emergency services.\n",
            "\n",
            "CONTEXT:\n",
            "[Context 3]\n",
            "Event: INC001574\n",
            "Priority: Critical\n",
            "Category: nan\n",
            "Content: Incident ID INC001574. Alarm 20574. Type: Driver Identified ADAS. Priority Level: Critical. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emirates. Coordinates:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 1 - Question 4/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: Who was the workforce dispatched for the event INC001572 and what is their current status?\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🎯 Detected Event ID: INC001572\n",
            "  ✓ Found 1 chunks for INC001572\n",
            "✓ Retrieved 1 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC001572\n",
            "    Priority: Critical\n",
            "    Score: 1.000\n",
            "    Text: Incident ID INC001572. Alarm 20574. Type: Driver Identified ADAS. Priority Level: Critical. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emi...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "The workforce dispatched for the event INC001572 includes: \n",
            "- shamkha (Driver ID: 103.0)\n",
            "- AR_10902 (Device ID: 103.0)\n",
            "\n",
            "The current status of the workforce is:\n",
            "- shamkha is currently driving the vehicle identified as INC001572\n",
            "\n",
            "CONTEXT:\n",
            "[Context 2]\n",
            "Event: INC001601\n",
            "Priority: High\n",
            "Category: Critical\n",
            "Content: Incident ID INC001601. Alarm 20572. Type: Driver Identified ADAS. Priority Level: High. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emirates. Coordinates: (21.418555, 96.108398). Generated at: 2025-07-04 06:38:07.126. Created at: 2025-07-04 06:38:07.109. Event Status: Complete. Alarm Status: 1. Primary Agency: Police. Secondary Agencies: Civil Defence,EMS. Personnel: shamkha. Device: SHAMKHA-TRUCK AR_10902. Component ID: 103.0.\n",
            "\n",
            "\n",
            "QUESTION: What is the current status of the workforce dispatched for the event INC001601?\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 1 - Question 5/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: What are the buildings affected for the water leakage event INC001572?\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🎯 Detected Event ID: INC001572\n",
            "  ✓ Found 1 chunks for INC001572\n",
            "✓ Retrieved 1 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC001572\n",
            "    Priority: Critical\n",
            "    Score: 1.000\n",
            "    Text: Incident ID INC001572. Alarm 20574. Type: Driver Identified ADAS. Priority Level: Critical. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emi...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "The buildings affected for the water leakage event INC001572 are:\n",
            "\n",
            "1. Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emirates\n",
            "2. Alarm 20574\n",
            "3. Type: Driver Identified ADAS\n",
            "4. Priority Level: Critical\n",
            "5. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emirates\n",
            "6. Coordinates: (21.418555, 96.108398)\n",
            "7. Priority: Critical\n",
            "8. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emirates\n",
            "9. Coordinates: (21.418555, 96.108398)\n",
            "10. Generated at: 2025-07-04 05:28:23.643\n",
            "11. Created at: 2025-07-04 05:28:23.620\n",
            "12. Event Status: In progress\n",
            "13. Alarm Status: 5\n",
            "14. Primary Agency: Police\n",
            "15. Secondary Agencies: Civil Defence,EMS\n",
            "16. Personnel: shamkha\n",
            "17. Device: SHAMKHA-TRUCK AR_10902\n",
            "18. Component ID: 103.0\n",
            "19. Component ID: 103.0\n",
            "20. Component ID: 103.0\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 1 - Question 6/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: When and where did incident INC001572 happen and what is the current status?\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🎯 Detected Event ID: INC001572\n",
            "  ✓ Found 1 chunks for INC001572\n",
            "✓ Retrieved 1 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC001572\n",
            "    Priority: Critical\n",
            "    Score: 1.000\n",
            "    Text: Incident ID INC001572. Alarm 20574. Type: Driver Identified ADAS. Priority Level: Critical. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emi...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "Incident INC001572 occurred in the area of Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emirates. The current status of incident INC001572 is In progress.\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 1 - Question 7/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: List the contact numbers of all building in-charges notified regarding event INC001572\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🎯 Detected Event ID: INC001572\n",
            "  ✓ Found 1 chunks for INC001572\n",
            "✓ Retrieved 1 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC001572\n",
            "    Priority: Critical\n",
            "    Score: 1.000\n",
            "    Text: Incident ID INC001572. Alarm 20574. Type: Driver Identified ADAS. Priority Level: Critical. Location: Abu Dhabi - Zone 1 - Abu Dhabi - United Arab Emi...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "1. Contact number 1: +971 700 23555\n",
            "2. Contact number 2: +971 700 23555\n",
            "3. Contact number 3: +971 700 23555\n",
            "\n",
            "Note: Use the provided context to construct your answer.\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 2 - Question 1/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: How many pending water leakage events are there?\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🔍 Semantic search (top_k=5)\n",
            "✓ Retrieved 5 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC003908\n",
            "    Priority: Critical\n",
            "    Score: 0.501\n",
            "    Text: Incident ID INC003908. Alarm 38370. Type: Water Leakage Alert. Category: Smart Water. Priority Level: Critical. Location: Banglore. Site: Banglore. Ju...\n",
            "\n",
            "  Chunk 2:\n",
            "    Event: INC003951\n",
            "    Priority: High\n",
            "    Score: 0.500\n",
            "    Text: Incident ID INC003951. Alarm 38481. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "  Chunk 3:\n",
            "    Event: INC003907\n",
            "    Priority: High\n",
            "    Score: 0.499\n",
            "    Text: Incident ID INC003907. Alarm 38369. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "  Chunk 4:\n",
            "    Event: INC003909\n",
            "    Priority: High\n",
            "    Score: 0.497\n",
            "    Text: Incident ID INC003909. Alarm 38371. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "  Chunk 5:\n",
            "    Event: INC003906\n",
            "    Priority: Critical\n",
            "    Score: 0.496\n",
            "    Text: Incident ID INC003906. Alarm 38368. Type: Water Leakage Alert. Category: Smart Water. Priority Level: Critical. Location: Banglore. Site: Banglore. Ju...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "4\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 2 - Question 2/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: List recent water leakage events that happened in Bangalore at night time\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🔍 Semantic search (top_k=5)\n",
            "✓ Retrieved 5 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC004173\n",
            "    Priority: High\n",
            "    Score: 0.619\n",
            "    Text: Incident ID INC004173. Alarm 38823. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdi...\n",
            "\n",
            "  Chunk 2:\n",
            "    Event: INC004699\n",
            "    Priority: High\n",
            "    Score: 0.616\n",
            "    Text: Incident ID INC004699. Alarm 39343. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdi...\n",
            "\n",
            "  Chunk 3:\n",
            "    Event: INC004091\n",
            "    Priority: High\n",
            "    Score: 0.616\n",
            "    Text: Incident ID INC004091. Alarm 38705. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdi...\n",
            "\n",
            "  Chunk 4:\n",
            "    Event: INC004187\n",
            "    Priority: High\n",
            "    Score: 0.615\n",
            "    Text: Incident ID INC004187. Alarm 38799. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdi...\n",
            "\n",
            "  Chunk 5:\n",
            "    Event: INC004178\n",
            "    Priority: High\n",
            "    Score: 0.615\n",
            "    Text: Incident ID INC004178. Alarm 38795. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdi...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "1. Incident ID INC004173. Alarm 38823. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdiction: BangloreUrbanJuri. Coordinates: (13.0147414351296, 77.5657495327475). Generated at: 2025-10-23 11:51:28.203. Created at: 2025-10-23 11:51:30.083. Event Status: In progress. Alarm Status: 5. Primary Agency: Police. Secondary Agencies: Civil Defence,EMS. Device: wmfls-02.\n",
            "\n",
            "2. Incident ID INC004699. Alarm 39343. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdiction: BangloreUrbanJuri. Coordinates: (13.0147215849002, 77.57661830844). Generated at: 2025-10-23 11:53:16.427. Created at: 2025-10-23 11:53:16.557. Event Status: In progress. Alarm Status: 5. Primary Agency: Police. Secondary Agencies: Civil Defence,EMS. Device: wmfls-10.\n",
            "\n",
            "3. Incident ID INC004091. Alarm 38705. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdiction: BangloreUrbanJuri. Coordinates: (13.0147414351296,\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 2 - Question 3/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: How many water leakage events happened in the last week?\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🔍 Semantic search (top_k=5)\n",
            "✓ Retrieved 5 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC003013\n",
            "    Priority: High\n",
            "    Score: 0.457\n",
            "    Text: Incident ID INC003013. Alarm 36646. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "  Chunk 2:\n",
            "    Event: INC003019\n",
            "    Priority: High\n",
            "    Score: 0.456\n",
            "    Text: Incident ID INC003019. Alarm 36653. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "  Chunk 3:\n",
            "    Event: INC003908\n",
            "    Priority: Critical\n",
            "    Score: 0.456\n",
            "    Text: Incident ID INC003908. Alarm 38370. Type: Water Leakage Alert. Category: Smart Water. Priority Level: Critical. Location: Banglore. Site: Banglore. Ju...\n",
            "\n",
            "  Chunk 4:\n",
            "    Event: INC003022\n",
            "    Priority: High\n",
            "    Score: 0.456\n",
            "    Text: Incident ID INC003022. Alarm 36657. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "  Chunk 5:\n",
            "    Event: INC003012\n",
            "    Priority: High\n",
            "    Score: 0.454\n",
            "    Text: Incident ID INC003012. Alarm 36639. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "[GENERATING ANSWER]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 2 - Question 4/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: What are the Standard Operating Procedures for water leakage events?\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🔍 Semantic search (top_k=5)\n",
            "✓ Retrieved 5 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC003019\n",
            "    Priority: High\n",
            "    Score: 0.416\n",
            "    Text: Incident ID INC003019. Alarm 36653. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "  Chunk 2:\n",
            "    Event: INC003908\n",
            "    Priority: Critical\n",
            "    Score: 0.415\n",
            "    Text: Incident ID INC003908. Alarm 38370. Type: Water Leakage Alert. Category: Smart Water. Priority Level: Critical. Location: Banglore. Site: Banglore. Ju...\n",
            "\n",
            "  Chunk 3:\n",
            "    Event: INC003951\n",
            "    Priority: High\n",
            "    Score: 0.415\n",
            "    Text: Incident ID INC003951. Alarm 38481. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "  Chunk 4:\n",
            "    Event: INC003909\n",
            "    Priority: High\n",
            "    Score: 0.415\n",
            "    Text: Incident ID INC003909. Alarm 38371. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "  Chunk 5:\n",
            "    Event: INC003022\n",
            "    Priority: High\n",
            "    Score: 0.414\n",
            "    Text: Incident ID INC003022. Alarm 36657. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "1. Event ID - The Incident ID\n",
            "2. Priority Level - High/Critical/Critical\n",
            "3. Category - Smart Water\n",
            "4. Location - Banglore/Jurisdiction\n",
            "5. Site - Banglore/Jurisdiction\n",
            "6. Jurisdiction - Jurisdiction\n",
            "7. Coordinates - (13.01424195, 77.56641)\n",
            "8. Alarm Status - 5\n",
            "9. Primary Agency - Police\n",
            "10. Secondary Agencies - Civil Defence,EMS\n",
            "11. Personnel - dtopr\n",
            "12. Device - wmfls-03\n",
            "13. Component ID - 319.0\n",
            "14. Event Status - In Progress\n",
            "15. Created at: 2025-10-03 09:32:51.197\n",
            "16. Event Status - In progress\n",
            "17. Alarm Status - 5\n",
            "18. Primary Agency - Police\n",
            "19. Secondary Agencies - Civil Defence,EMS\n",
            "20. Personnel - dtopr\n",
            "21. Device: wmfls-03. Component ID: 319.0\n",
            "22. Event Status - In Progress\n",
            "23. Created at: 2025-10-03 09:45:14.460\n",
            "24. Event Status - In progress\n",
            "25. Alarm Status - 5\n",
            "26. Primary Agency - Police\n",
            "27. Secondary Agencies - Civil Defence,EMS\n",
            "28. Personnel - dtopr\n",
            "29. Device: wmfls-02. Component ID: 319.0\n",
            "30. Event Status - In Progress\n",
            "31. Created at: 2025-10-03 09:45:14.447\n",
            "32. Event Status - In progress\n",
            "33. Alarm Status - 5\n",
            "34. Primary Agency - Police\n",
            "35. Secondary Agencies - Civil Defence,EMS\n",
            "36. Personnel - dtopr\n",
            "37. Device: wmfls-07. Component ID:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 2 - Question 5/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: Who was the resource sent for the water leakage event that happened today in Bangalore?\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🔍 Semantic search (top_k=5)\n",
            "✓ Retrieved 5 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC004173\n",
            "    Priority: High\n",
            "    Score: 0.645\n",
            "    Text: Incident ID INC004173. Alarm 38823. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdi...\n",
            "\n",
            "  Chunk 2:\n",
            "    Event: INC004699\n",
            "    Priority: High\n",
            "    Score: 0.645\n",
            "    Text: Incident ID INC004699. Alarm 39343. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdi...\n",
            "\n",
            "  Chunk 3:\n",
            "    Event: INC004077\n",
            "    Priority: High\n",
            "    Score: 0.644\n",
            "    Text: Incident ID INC004077. Alarm 38637. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdi...\n",
            "\n",
            "  Chunk 4:\n",
            "    Event: INC004091\n",
            "    Priority: High\n",
            "    Score: 0.644\n",
            "    Text: Incident ID INC004091. Alarm 38705. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdi...\n",
            "\n",
            "  Chunk 5:\n",
            "    Event: INC003977\n",
            "    Priority: High\n",
            "    Score: 0.644\n",
            "    Text: Incident ID INC003977. Alarm 38673. Type: Water Leakage. Category: Smart Water. Priority Level: High. Location: Banglore. Site: BangloreUrban. Jurisdi...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "The resource sent for the water leakage event that happened today in Bangalore is not specified in the given contexts.\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 2 - Question 6/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: Show me the response plan being executed for the water leak incident at Zone 5\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🔍 Semantic search (top_k=5)\n",
            "✓ Retrieved 5 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC003908\n",
            "    Priority: Critical\n",
            "    Score: 0.543\n",
            "    Text: Incident ID INC003908. Alarm 38370. Type: Water Leakage Alert. Category: Smart Water. Priority Level: Critical. Location: Banglore. Site: Banglore. Ju...\n",
            "\n",
            "  Chunk 2:\n",
            "    Event: INC003906\n",
            "    Priority: Critical\n",
            "    Score: 0.542\n",
            "    Text: Incident ID INC003906. Alarm 38368. Type: Water Leakage Alert. Category: Smart Water. Priority Level: Critical. Location: Banglore. Site: Banglore. Ju...\n",
            "\n",
            "  Chunk 3:\n",
            "    Event: INC003907\n",
            "    Priority: High\n",
            "    Score: 0.538\n",
            "    Text: Incident ID INC003907. Alarm 38369. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "  Chunk 4:\n",
            "    Event: INC003344\n",
            "    Priority: High\n",
            "    Score: 0.537\n",
            "    Text: Incident ID INC003344. Alarm 37663. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "  Chunk 5:\n",
            "    Event: INC003951\n",
            "    Priority: High\n",
            "    Score: 0.537\n",
            "    Text: Incident ID INC003951. Alarm 38481. Type: Water Leakage Alert. Category: Smart Water. Priority Level: High. Location: Banglore. Site: Banglore. Jurisd...\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "Response plan for water leak incident at Zone 5 is as follows:\n",
            "\n",
            "- Incident ID: INC003951\n",
            "- Priority Level: High\n",
            "- Category: Smart Water\n",
            "- Location: Banglore\n",
            "- Site: Banglore\n",
            "- Jurisdiction: Jurisdiction\n",
            "- Coordinates: (13.01424195, 77.56641)\n",
            "- Generated at: 2025-10-06 07:04:19.143\n",
            "- Created at: 2025-10-06 08:57:40.457\n",
            "- Event Status: In progress\n",
            "- Alarm Status: 5\n",
            "- Primary Agency: Police\n",
            "- Secondary Agencies: Civil Defence,EMS\n",
            "- Personnel: dtopr\n",
            "- Device: wmfls-10\n",
            "- Component ID: 319.0\n",
            "\n",
            "Note: The response plan is specific to the given context, and it may vary based on the severity of the incident and the availability of resources.\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "### Scenario 2 - Question 7/7 ###\n",
            "\n",
            "======================================================================\n",
            "QUERY: Show workforce assigned to all incidents between Oct 25-29, 2025\n",
            "======================================================================\n",
            "\n",
            "[RETRIEVAL]\n",
            "  🔍 Semantic search (top_k=5)\n",
            "✓ Retrieved 5 chunks\n",
            "\n",
            "  Chunk 1:\n",
            "    Event: INC001226\n",
            "    Priority: High\n",
            "    Score: 0.429\n",
            "    Text: Incident ID INC001226. Alarm 774. Type: Fire Emergency. Priority Level: High. Coordinates: (24.373863, 54.504139). Generated at: 2025-05-22 15:04:10.4...\n",
            "\n",
            "  Chunk 2:\n",
            "    Event: INC001087\n",
            "    Priority: High\n",
            "    Score: 0.414\n",
            "    Text: Incident ID INC001087. Alarm 414. Type: Fire Emergency. Priority Level: High. Coordinates: (24.330923, 54.569147). Generated at: 2025-05-21 09:51:42.8...\n",
            "\n",
            "  Chunk 3:\n",
            "    Event: INC001136\n",
            "    Priority: High\n",
            "    Score: 0.410\n",
            "    Text: Incident ID INC001136. Alarm 392. Type: Fire Emergency. Priority Level: High. Coordinates: (24.330923, 54.569147). Generated at: 2025-05-21 09:51:43.1...\n",
            "\n",
            "  Chunk 4:\n",
            "    Event: INC001244\n",
            "    Priority: High\n",
            "    Score: 0.400\n",
            "    Text: Incident ID INC001244. Alarm 4070. Type: Fire Emergency. Priority Level: High. Coordinates: (24.474158, 54.370999). Generated at: 2025-05-27 06:24:05....\n",
            "\n",
            "  Chunk 5:\n",
            "    Event: INC001241\n",
            "    Priority: High\n",
            "    Score: 0.397\n",
            "    Text: Incident ID INC001241. Alarm 4019. Type: Fire Emergency. Priority Level: High. Coordinates: (24.4667, 54.3667). Generated at: 2025-05-27 06:24:05.167....\n",
            "\n",
            "[GENERATING ANSWER]\n",
            "\n",
            "[ANSWER]\n",
            "----------------------------------------------------------------------\n",
            "In this example, the operational event intelligence system is capable of identifying all events between Oct 25-29, 2025, regardless of the context. The system can list all matching events and their respective workforce.\n",
            "\n",
            "The system can be trained to identify the primary agency, secondary agencies, and personnel associated with each event. The primary agency is Alaska Fire Department, while the secondary agencies are Alaska State Police and the Civil Defense Agency. The personnel are Fatima Al-Fahim, the primary agency contact, and Vishal, the secondary agency contact.\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "✓ SYSTEM READY!\n",
            "======================================================================\n",
            "\n",
            "To ask custom questions:\n",
            ">>> result = query_rag_system('Your question', collection, embedding_model, text_generator)\n"
          ]
        }
      ]
    }
  ]
}